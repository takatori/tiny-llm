{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "289f5834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# 1つ上の階層 (project/) を sys.path に追加\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "158ab739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "\n",
    "    # The book originally contained this unnecessary \"else\" clause:\n",
    "    #else:\n",
    "    #    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    #        text_data = file.read()\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68535666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task.\"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = (\n",
    "        f\"\\n\\n### Input:\\n{entry['input']}\"\n",
    "        if entry[\"input\"]\n",
    "        else \"\"\n",
    "    )\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11cd44ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task.Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[50])\n",
    "described_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "print(model_input + described_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0c764f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 935\n",
      "Test data size: 110\n",
      "Validation data size: 55\n"
     ]
    }
   ],
   "source": [
    "train_portion = int(len(data) * 0.85)\n",
    "test_portion = int(len(data) *  0.1)\n",
    "val_portion = len(data) - train_portion - test_portion\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]\n",
    "\n",
    "print(\"Train data size:\", len(train_data))\n",
    "print(\"Test data size:\", len(test_data))\n",
    "print(\"Validation data size:\", len(val_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abae3e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):        \n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(tokenizer.encode(full_text))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea87c63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb2ca65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_1(batch, pad_token_id=50256, device=\"cpu\"):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst = []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        inputs_lst.append(inputs)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device) # 入力リストをテンソルに変換し、ターゲットデバイスに転送\n",
    "    return inputs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f3e344d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "print(custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fee6c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_2(batch, pad_token_id=50256, device=\"cpu\"):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "    \n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)  \n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b7f92cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_draft_2(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa02052f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch, pad_token_id=50256, ignore_index=-100, allowed_max_length=None,  device=\"cpu\"):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1: # numelは要素数を返す\n",
    "            targets[indices[1:]] = ignore_index # 2番目以降の要素をignore_indexに設定\n",
    "\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]            \n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "    \n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)  \n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c4b1cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "67eb3b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# if torch.backends.mps.is_available():\n",
    "    # device = torch.device(\"mps\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a13a77c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "customized_collate_fn = partial(\n",
    "    custom_collate_fn,\n",
    "    device=device,\n",
    "    allowed_max_length=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e3241c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,    \n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,    \n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,    \n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "976a4269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_dataloader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dfd68012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/355M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/355M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/355M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/355M/vocab.bpe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 1024)\n",
       "  (pos_emb): Embedding(1024, 1024)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from tiny_llm.gpt_model import GPTModel\n",
    "from tiny_llm.utils import load_weights_into_gpt\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate_emb\": 0.0,      \n",
    "    \"drop_rate_attn\": 0.0,     \n",
    "    \"drop_rate_shortcut\": 0.0, \n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size,\n",
    "    models_dir=\"gpt2\"\n",
    ")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "968925ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task.Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2f07eb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active\n"
     ]
    }
   ],
   "source": [
    "from tiny_llm.utils import generate, text_to_token_ids, token_ids_to_text\n",
    "\n",
    "token_ids = generate(\n",
    "    model = model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "\n",
    "response_text = generated_text[len(input_text):].strip()\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b0af6208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0135386943817135\n",
      "Validation loss: 3.938512849807739\n"
     ]
    }
   ],
   "source": [
    "from tiny_llm.utils import calc_loss_loader, train_model_simple\n",
    "\n",
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(\n",
    "        train_dataloader, model, device, num_batches=5\n",
    "    )\n",
    "    val_loss = calc_loss_loader(\n",
    "        val_dataloader, model, device, num_batches=5\n",
    "    )\n",
    "\n",
    "print(\"Train loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b537e448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss: 2.776, Val loss: 2.755\n",
      "Ep 1 (Step 000005): Train loss: 1.207, Val loss: 1.138\n",
      "Ep 1 (Step 000010): Train loss: 0.872, Val loss: 0.968\n",
      "Ep 1 (Step 000015): Train loss: 0.856, Val loss: 0.907\n",
      "Ep 1 (Step 000020): Train loss: 0.788, Val loss: 0.910\n",
      "Ep 1 (Step 000025): Train loss: 0.775, Val loss: 0.866\n",
      "Ep 1 (Step 000030): Train loss: 0.801, Val loss: 0.841\n",
      "Ep 1 (Step 000035): Train loss: 0.716, Val loss: 0.813\n",
      "Ep 1 (Step 000040): Train loss: 0.669, Val loss: 0.803\n",
      "Ep 1 (Step 000045): Train loss: 0.634, Val loss: 0.792\n",
      "Ep 1 (Step 000050): Train loss: 0.663, Val loss: 0.785\n",
      "Ep 1 (Step 000055): Train loss: 0.763, Val loss: 0.772\n",
      "Ep 1 (Step 000060): Train loss: 0.721, Val loss: 0.749\n",
      "Ep 1 (Step 000065): Train loss: 0.651, Val loss: 0.739\n",
      "Ep 1 (Step 000070): Train loss: 0.532, Val loss: 0.731\n",
      "Ep 1 (Step 000075): Train loss: 0.566, Val loss: 0.732\n",
      "Ep 1 (Step 000080): Train loss: 0.604, Val loss: 0.723\n",
      "Ep 1 (Step 000085): Train loss: 0.511, Val loss: 0.706\n",
      "Ep 1 (Step 000090): Train loss: 0.564, Val loss: 0.692\n",
      "Ep 1 (Step 000095): Train loss: 0.502, Val loss: 0.685\n",
      "Ep 1 (Step 000100): Train loss: 0.501, Val loss: 0.679\n",
      "Ep 1 (Step 000105): Train loss: 0.567, Val loss: 0.673\n",
      "Ep 1 (Step 000110): Train loss: 0.554, Val loss: 0.667\n",
      "Ep 1 (Step 000115): Train loss: 0.509, Val loss: 0.666\n",
      "Below is an instruction that describes a task.Write a response that appropriately completes the request.### Instruction:Convert the active sentence to passive: 'The chef cooks the meal every day.'### Response:The meal is prepared every day by the chef.<|endoftext|>The following is an instruction that describes a task.Write a response that appropriately completes the request.### Instruction:Convert the active sentence to passive:\n",
      "Ep 2 (Step 000120): Train loss: 0.434, Val loss: 0.671\n",
      "Ep 2 (Step 000125): Train loss: 0.446, Val loss: 0.687\n",
      "Ep 2 (Step 000130): Train loss: 0.449, Val loss: 0.681\n",
      "Ep 2 (Step 000135): Train loss: 0.411, Val loss: 0.678\n",
      "Ep 2 (Step 000140): Train loss: 0.413, Val loss: 0.677\n",
      "Ep 2 (Step 000145): Train loss: 0.369, Val loss: 0.679\n",
      "Ep 2 (Step 000150): Train loss: 0.377, Val loss: 0.675\n",
      "Ep 2 (Step 000155): Train loss: 0.411, Val loss: 0.675\n",
      "Ep 2 (Step 000160): Train loss: 0.408, Val loss: 0.683\n",
      "Ep 2 (Step 000165): Train loss: 0.375, Val loss: 0.688\n",
      "Ep 2 (Step 000170): Train loss: 0.323, Val loss: 0.686\n",
      "Ep 2 (Step 000175): Train loss: 0.339, Val loss: 0.671\n",
      "Ep 2 (Step 000180): Train loss: 0.390, Val loss: 0.658\n",
      "Ep 2 (Step 000185): Train loss: 0.417, Val loss: 0.659\n",
      "Ep 2 (Step 000190): Train loss: 0.338, Val loss: 0.649\n",
      "Ep 2 (Step 000195): Train loss: 0.330, Val loss: 0.632\n",
      "Ep 2 (Step 000200): Train loss: 0.308, Val loss: 0.629\n",
      "Ep 2 (Step 000205): Train loss: 0.350, Val loss: 0.624\n",
      "Ep 2 (Step 000210): Train loss: 0.374, Val loss: 0.625\n",
      "Ep 2 (Step 000215): Train loss: 0.399, Val loss: 0.632\n",
      "Ep 2 (Step 000220): Train loss: 0.303, Val loss: 0.647\n",
      "Ep 2 (Step 000225): Train loss: 0.338, Val loss: 0.661\n",
      "Ep 2 (Step 000230): Train loss: 0.293, Val loss: 0.655\n",
      "Below is an instruction that describes a task.Write a response that appropriately completes the request.### Instruction:Convert the active sentence to passive: 'The chef cooks the meal every day.'### Response:The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task.Write a response that appropriately completes the request.### Instruction:What is the capital of the United Kingdom\n",
      "Training completed in 13.53 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)  \n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=0.00005,\n",
    "    weight_decay=0.1,\n",
    ")  \n",
    "num_epochs = 2\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model=model,\n",
    "    train_loader=train_dataloader,\n",
    "    val_loader=val_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=num_epochs,\n",
    "    eval_freq=5,\n",
    "    eval_iter=5,\n",
    "    start_context=format_input(val_data[0]),\n",
    "    tokenizer=tokenizer,    \n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a3015be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tiny_llm.utils import plot_losses\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "16765c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task.Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">>The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">>:\n",
      "The car is as fast as a bullet.\n",
      "--------------------------------------------------------------------------------\n",
      "Below is an instruction that describes a task.Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">>The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">>:\n",
      "The type of cloud associated with thunderstorms is a cumulus cloud.\n",
      "--------------------------------------------------------------------------------\n",
      "Below is an instruction that describes a task.Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">>Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">>:\n",
      "The author of 'Pride and Prejudice' is Jane Austen.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "    input_text = format_input(entry)    \n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256,\n",
    "    )\n",
    "\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response\", \"\").strip()\n",
    "    \n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>>{entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>>{response_text.strip()}\")\n",
    "    print(\"-\" * 80)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8880a279",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [05:31<00:00,  3.01s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "    input_text = format_input(entry)    \n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256,\n",
    "    )\n",
    "\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response\", \"\").strip()\n",
    "\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "with open(\"instruction-data-with-response.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(test_data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bcfe6587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as gpt2-medium355M-sft.path\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL)}-sft.path\"\n",
    "torch.save(model.state_dict(), file_name)\n",
    "print(f\"Model saved as {file_name}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fc37b318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "\n",
    "def check_if_runnning(process_name):\n",
    "    running = False\n",
    "    for proc in psutil.process_iter(['name']):\n",
    "        if proc.info['name'] == process_name:\n",
    "            running = True\n",
    "            break\n",
    "    return running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "641919ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama running: True\n"
     ]
    }
   ],
   "source": [
    "ollama_running = check_if_runnning(\"ollama\")\n",
    "\n",
    "if not ollama_running:\n",
    "    raise RuntimeError(\n",
    "        \"Ollama is not running. Please start Ollama before running this code.\"\n",
    "    )\n",
    "\n",
    "print(\"Ollama running:\", check_if_runnning(\"ollama\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ffbad6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "def query_model(prompt, model=\"llama3\", url=\"http://localhost:11434/api/chat\"):\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"options\": {\n",
    "            \"seed\": 123,\n",
    "            \"temperature\": 0,\n",
    "            \"num_ctx\": 2048\n",
    "        }\n",
    "    }\n",
    "\n",
    "    payload = json.dumps(data).encode('utf-8')\n",
    "\n",
    "    request = urllib.request.Request(\n",
    "        url,\n",
    "        data=payload,\n",
    "        method='POST',\n",
    "    )\n",
    "    request.add_header('Content-Type', 'application/json')\n",
    "\n",
    "    response_data = \"\"\n",
    "    with urllib.request.urlopen(request) as response:\n",
    "        while True:\n",
    "            line = response.readline().decode('utf-8')\n",
    "            if not line:\n",
    "                break\n",
    "            response_json = json.loads(line)\n",
    "            response_data += response_json[\"message\"][\"content\"]\n",
    "\n",
    "    return response_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "36fa87c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llamas are herbivores, which means they primarily eat plants and plant-based foods. Their diet typically consists of:\n",
      "\n",
      "1. Grasses: Llamas love to graze on various types of grasses, including tall grasses, short grasses, and grassy weeds.\n",
      "2. Hay: High-quality hay, such as timothy hay or alfalfa hay, is a staple in a llama's diet. It provides essential nutrients like fiber, protein, and vitamins.\n",
      "3. Grains: Llamas may also be fed grains like oats, barley, or corn, but these should not make up more than 10% of their diet.\n",
      "4. Fruits and vegetables: Fresh fruits and vegetables, such as apples, carrots, and sweet potatoes, can be given to llamas as treats or added to their hay.\n",
      "5. Browse: Llamas may also eat browse, which includes leaves, twigs, and other vegetation from trees and shrubs.\n",
      "\n",
      "It's essential to note that llamas have a unique digestive system, with a four-chambered stomach, which allows them to break down and extract nutrients from plant material more efficiently than many other animals. However, this also means they can be prone to certain health issues if their diet is not balanced or if they eat too much of the wrong foods.\n",
      "\n",
      "A good rule of thumb for llama owners is to provide a high-quality hay-based diet with limited amounts of grains and treats, and to ensure access to fresh water at all times.\n"
     ]
    }
   ],
   "source": [
    "model = \"llama3.2\"\n",
    "result = query_model(\"What do Llamas eat?\", model=model)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a8b6a2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset response:\n",
      ">>> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">>> :\n",
      "The car is as fast as a bullet.\n",
      "\n",
      "Score:\n",
      ">>> To score the model response, I would give it a score of 80 out of 100.\n",
      "\n",
      "Here's why:\n",
      "\n",
      "* The response \"The car is as fast as a bullet\" uses a simile to compare the speed of the car to that of a bullet, which is a common and effective way to describe something as being very fast.\n",
      "* However, the comparison to a bullet might not be the most accurate or evocative choice, as bullets are typically associated with high-velocity projectiles rather than speed. A more fitting simile for describing a car's speed might be one that emphasizes its acceleration or top-end velocity.\n",
      "\n",
      "A better response would have been \"The car is as fast as lightning\" (as provided in the correct output), which uses a more vivid and accurate comparison to convey the idea of extremely rapid movement.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Dataset response:\n",
      ">>> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">>> :\n",
      "The type of cloud associated with thunderstorms is a cumulus cloud.\n",
      "\n",
      "Score:\n",
      ">>> I would rate the model response as 20 out of 100.\n",
      "\n",
      "Here's why:\n",
      "\n",
      "1. The model response contains incorrect information: Cumulonimbus clouds are indeed associated with thunderstorms, but cumulus clouds are typically associated with fair weather.\n",
      "2. Lack of specificity: The model response is too vague and does not provide a clear answer to the question.\n",
      "3. Inaccuracy in terminology: The term \"cumulus cloud\" is used incorrectly; it should be \"cumulus\" without the definite article.\n",
      "\n",
      "A more accurate response would be:\n",
      "\n",
      "\"The type of cloud typically associated with thunderstorms is cumulonimbus.\"\n",
      "\n",
      "This response is correct, specific, and uses the correct terminology.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Dataset response:\n",
      ">>> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">>> :\n",
      "The author of 'Pride and Prejudice' is Jane Austen.\n",
      "\n",
      "Score:\n",
      ">>> Score: 100\n",
      "\n",
      "Reasoning:\n",
      "\n",
      "* The model's response directly answers the question by providing the name of the author.\n",
      "* The response is concise and to the point, without any unnecessary information.\n",
      "* The format of the response matches the expected output, with the correct answer followed by a period.\n",
      "\n",
      "Overall, the model's response is accurate, clear, and well-structured, which is why it scores 100 out of 100.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for entry in test_data[:3]:\n",
    "    prompt = (\n",
    "        f\"Given the input `{format_input(entry)}`\"\n",
    "        f\"and correct output `{entry['output']}`,\"\n",
    "        f\"score the model response `{entry['model_response']}`\"\n",
    "        f\"on a scale from 0 to 100, where 100 is the best score.\"\n",
    "    )\n",
    "    print(\"\\nDataset response:\")\n",
    "    print(\">>>\", entry[\"output\"])\n",
    "    print(\"\\nModel response:\")\n",
    "    print(\">>>\", entry[\"model_response\"])\n",
    "    print(\"\\nScore:\")\n",
    "    print(\">>>\", query_model(prompt, model=model))\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1fe2fff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_scores(json_data, json_key, model=\"llama3.2\"):\n",
    "    scores = []\n",
    "    for entry in tqdm(json_data, desc=\"Generating scores\"):\n",
    "        prompt = (\n",
    "            f\"Given the input `{format_input(entry)}`\"\n",
    "            f\"and correct output `{entry['output']}`,\"\n",
    "            f\"score the model response `{entry[json_key]}`\"\n",
    "            f\"on a scale from 0 to 100, where 100 is the best score.\"\n",
    "            f\"Respond with the integer number only.\"\n",
    "        )\n",
    "        score = query_model(prompt, model=model)\n",
    "        try:\n",
    "            scores.append(int(score))\n",
    "        except ValueError:\n",
    "            print(f\"Invalid score received: {score}\")\n",
    "            continue\n",
    "    return scores    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1abef781",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating scores:   1%|          | 1/110 [00:02<04:05,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid score received: 80\n",
      "\n",
      "Explanation: The original sentence \"The car is very fast\" can be rewritten using a simile as \"The car is as fast as lightning\". This response is close but not perfect because it doesn't use the word \"as\" which is necessary for a simile. A better response would be \"The car is as fast as a bullet.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating scores:  10%|█         | 11/110 [00:06<01:02,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid score received: 60\n",
      "\n",
      "Explanation: The correct classification should include both prime and composite numbers. The given input \"Prime: 11\" is partially correct but misses the prime number \"19\". It also incorrectly classifies \"14\" as a composite number, when in fact it's a composite number itself. A more accurate response would be:\n",
      "\n",
      " Prime numbers: 11, 19\n",
      " Composite numbers: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating scores:  16%|█▋        | 18/110 [00:09<01:08,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid score received: 80\n",
      "\n",
      "The corrected sentence uses an indefinite pronoun \"someone\" instead of the definite article \"a\". The original sentence \"Someone left a note.\" is close but does not use an indefinite pronoun. The corrected response \"A note was left by someone.\" meets the request, but it's still slightly different from the ideal response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating scores:  23%|██▎       | 25/110 [00:12<00:49,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid score received: 60\n",
      "\n",
      "The model response \"Están libros\" translates to \"There are books\", which is not correct for the task of translating \"library\" into Spanish. The correct translation is \"biblioteca\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating scores:  25%|██▍       | 27/110 [00:14<01:01,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid score received: 60\n",
      "\n",
      "The model's response is partially correct, but it doesn't provide the actual translation. A more accurate response would be \"The Russian translation of 'Hello' is 'Привет' (Privet).\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating scores:  40%|████      | 44/110 [00:18<00:16,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid score received: Score: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating scores:  44%|████▎     | 48/110 [00:19<00:22,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid score received: I would categorize \"What a beautiful day!\" as an exclamation.\n",
      "\n",
      "Score: 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating scores:  45%|████▌     | 50/110 [00:20<00:23,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid score received: The synonym for \"begin\" is \"commence\".\n",
      "\n",
      "Score: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating scores:  47%|████▋     | 52/110 [00:22<00:48,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid score received: 80\n",
      "\n",
      "The model response \"Could you help me tomorrow?\" correctly transforms the input sentence into a question using \"could.\" It also adds the correct verb conjugation (\"help\") and maintains the original meaning of the sentence. The only minor improvement could be adding an apostrophe to \"you're\" (you are), but that's not necessary in this case.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating scores:  65%|██████▍   | 71/110 [00:27<00:13,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid score received: The corrected sentence is: \"I prefer homemade cookies to store bought.\"\n",
      "\n",
      "Score: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating scores:  70%|███████   | 77/110 [00:30<00:27,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid score received: I would give this model response a score of 20.\n",
      "\n",
      "The reason for this low score is that the model's response does not create a simile with the word \"as cold as\". Instead, it provides a factual piece of information about temperature. A good response should use the given phrase to create a comparison between two things, like in the correct output: \"Her hands were as cold as ice.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating scores:  71%|███████   | 78/110 [00:31<00:25,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid score received: Swim: Verb\n",
      "Beautiful: Adjective\n",
      "Quickly: Adverb\n",
      "\n",
      "Score: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating scores:  72%|███████▏  | 79/110 [00:33<00:34,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid score received: I would give this response a score of 60.\n",
      "\n",
      "Here's why:\n",
      "\n",
      "- The response provides the correct formula for calculating density (mass/volume).\n",
      "- It includes the units in the answer.\n",
      "- However, it does not provide the actual calculation or the result of the calculation, which is necessary to determine the density of the object.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating scores:  76%|███████▋  | 84/110 [00:35<00:20,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid score received: 80\n",
      "\n",
      "The input sentence \"He was as cool as a cucumber\" uses the clichéd expression \"as cool as a cucumber,\" which means being calm and composed. The corrected response \"He remained very calm\" avoids this cliché and conveys the same idea in a more original way.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating scores:  85%|████████▍ | 93/110 [00:38<00:05,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid score received: Score: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating scores:  95%|█████████▍| 104/110 [00:43<00:05,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid score received: The correct translation of \"see you later\" into Spanish is indeed \"hasta luego\".\n",
      "\n",
      "As for the model response \"Están leyendo see you later.\", I would score it a 0 out of 100.\n",
      "\n",
      "This response is incorrect because:\n",
      "\n",
      "* It doesn't translate the phrase \"see you later\", but rather states that people are reading the phrase.\n",
      "* The word \"leyendo\" means \"reading\", not translating.\n",
      "\n",
      "Therefore, the score is 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating scores:  98%|█████████▊| 108/110 [00:45<00:01,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid score received: I would classify the sentence \"Please open the door.\" as imperative because it is a command or request.\n",
      "\n",
      "Score: 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating scores: 100%|██████████| 110/110 [00:45<00:00,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scores: 93 of 110\n",
      "Average score: 49.68\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "scores = generate_model_scores(test_data, \"model_response\")\n",
    "print(f\"Number of scores: {len(scores)} of {len(test_data)}\")\n",
    "print(f\"Average score: {sum(scores) / len(scores):.2f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiny-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
